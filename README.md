## **Bank Churn MLops: FastAPI + Docker + Render Cloud** ğŸ§‘â€ğŸ’»â˜ï¸
![capachurn2](https://github.com/user-attachments/assets/64f585e9-246f-4147-8c13-59853454e316)

Esse projeto foi desenvolvido afim de prever evasÃ£o (churn) em um ambiente bancÃ¡rio. A soluÃ§Ã£o foi desenvolvida com o foco em aplicaÃ§Ã£o de prÃ¡ticas de MLOps, garantindo reprodutibilidade, escalabilidade e facilidade de manutenÃ§Ã£o ao longo do ciclo de vida do modelo.

A proposta contempla todas as etapas essenciais de um pipeline moderno de machine learning orientado a produÃ§Ã£o:

- PreparaÃ§Ã£o de dados: coleta, limpeza e transformaÃ§Ã£o.

- Desenvolvimento e validaÃ§Ã£o do modelo com abordagem modular.

- SerializaÃ§Ã£o com joblib. 

- Deploy da API com FastAPI, tornando o modelo acessÃ­vel via HTTP.

- ContainerizaÃ§Ã£o com Docker, permitindo portabilidade e integraÃ§Ã£o com pipelines de CI/CD.

- AutomatizaÃ§Ã£o com scripts e pre-commit hooks, seguindo boas prÃ¡ticas de versionamento e padronizaÃ§Ã£o.

## Estrutura do projeto ğŸ—‚ï¸

.
â”œâ”€â”€ data/                            
â”œâ”€â”€ model/                          
â”‚   â”œâ”€â”€ train.py                    
â”‚   â””â”€â”€ predict.py                  
â”œâ”€â”€ notebook/                        
â”‚   â””â”€â”€ jupyter_notebook.ipynb      
â”œâ”€â”€ main.py                         
â”œâ”€â”€ modelo_gradientBoost.pkl         
â”œâ”€â”€ requirements.txt                 
â”œâ”€â”€ install.sh                      
â”œâ”€â”€ dockerfile                       
â”œâ”€â”€ .dockerignore                    
â”œâ”€â”€ .gitignore                      
â”œâ”€â”€ .pre-commit-config.yaml          
â”œâ”€â”€ README.md                        
â””â”€â”€ venv/                            

## Tecnologias usadas

![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![Render](https://img.shields.io/badge/Render-%46E3B7.svg?style=for-the-badge&logo=render&logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)
![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)

## MÃ©tricas do modelo 

Primeiramente, foi realizado um estudo com diversos modelos de classificaÃ§Ã£o. Em um primeiro momento, foram selecionados os trÃªs melhores modelos: Ãrvore de DecisÃ£o, LightGBM e Gradient Boosting.

Abaixo estÃ¡ a curva ROC AUC dos modelos: 

![image](https://github.com/user-attachments/assets/8128e8dd-6423-421b-8a43-ff3f3242fc85)

Abaixo estÃ£o as mÃ©tricas principais de cada um:

| Modelo                | AcurÃ¡cia | F1-Score | Recall | Precision | ROC AUC |
| --------------------- | -------- | -------- | ------ | --------- | ------- |
| **Random Forest**     | 0.8515   | 0.6077   | 0.5399 | 0.6949    | 0.7379  |
| **Gradient Boosting** | 0.8055   | 0.6145   | 0.7277 | 0.5317    | 0.7771  |
| **LightGBM**          | 0.8225   | 0.6243   | 0.6925 | 0.5684    | 0.7751  |

Como estamos lidando com um problema de churn, o principal objetivo Ã© identificar corretamente a maior quantidade possÃ­vel de clientes que estÃ£o propensos a sair. Por esse motivo, foi dada prioridade Ã  mÃ©trica de recall, que mede a capacidade do modelo em capturar os casos positivos.
Dessa forma, o modelo escolhido para deploy foi o Gradient Boosting, por apresentar o melhor desempenho em recall entre os modelos avaliados.

**Tratamento de classes desbalanceadas** 

Para o tratamento do desbalanceamento de classes, foram realizados testes com diferentes estratÃ©gias, como RandomOversampling e RandomUndersampling.
AtravÃ©s desses experimentos, foi possÃ­vel identificar que a tÃ©cnica de RandomOversampling proporcionou as melhores mÃ©tricas de desempenho para o modelo selecionado (Gradient Boosting), especialmente no que diz respeito ao recall e ao F1-Score.







                   
